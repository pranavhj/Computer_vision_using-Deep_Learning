{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Dogimages = [cv2.imread(file) for file in glob.glob(r\"dl_data/PetImages/Dog/*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CATEGORIES)\n",
    "CATEGORIES=[str(file).replace(\"dl_data/fruits-360/Training\\\\\",\"\") for file in glob.glob(r\"dl_data/fruits-360/Training/*\")]\n",
    "len(CATEGORIES)\n",
    "#CATEGORIES=CATEGORIES[0:8]\n",
    "#print(CATEGORIES)\n",
    "training_data=[]\n",
    "for i in range(len(CATEGORIES)-1):\n",
    "    [training_data.append([cv2.imread(file),i]) for file in glob.glob(r\"dl_data/fruits-360/Training/\"+CATEGORIES[i]+\"/*.jp*g\")]\n",
    "   \n",
    "#print(np.shape(training_data[0][0]))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "56\n",
      "113\n",
      "87\n",
      "29\n",
      "81\n",
      "109\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "for s in training_data[0:8]:\n",
    "    print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59751, 100, 100, 3)\n",
      "(59751, 100, 100)\n",
      "(59751, 100, 100, 3)\n",
      "(59751,)\n"
     ]
    }
   ],
   "source": [
    "X=[];y=[];\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "print(np.shape(X))\n",
    "Xnew=[]\n",
    "for img in X:\n",
    "    Xnew.append(img[:,:,1])\n",
    "    \n",
    "print(np.shape(Xnew))\n",
    "#X=Xnew\n",
    "X=np.array(X).reshape(-3,100,100,3)\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59751, 100, 100, 3)\n",
      "(None, 3, 3, 512)\n",
      "(None, 4608)\n",
      "Train on 47800 samples, validate on 11951 samples\n",
      "Epoch 1/2\n",
      "47800/47800 [==============================] - 5699s 119ms/sample - loss: 0.3037 - accuracy: 0.9475 - val_loss: 0.0120 - val_accuracy: 0.9980\n",
      "Epoch 2/2\n",
      "47800/47800 [==============================] - 38816s 812ms/sample - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1f2bd7d88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X/255.0)\n",
    "y=np.array(y)\n",
    "print(X.shape)\n",
    "\n",
    "vgg = VGG16(input_shape=X.shape[1:], weights='imagenet', include_top=False)\n",
    "#res = ResNet50(input_shape=X.shape[1:], weights='imagenet', include_top=False)\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "print(np.shape(vgg.output))\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "print(np.shape(x))\n",
    "prediction = Dense(np.shape(X)[0], activation='softmax')(x)\n",
    "\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "#model.summary()\n",
    "\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "model.fit(X,y,epochs=2,validation_split=0.2)\n",
    "# model=tf.keras.models.Sequential()\n",
    "\n",
    "# model.add(  Conv2D(64,(3,3), input_shape=X.shape[1:])  )   \n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(64,(3,3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation(\"sigmoid\"))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#              optimizer=\"adam\",\n",
    "#              metrics=['accuracy'])\n",
    "# model.fit(X,y,batch_size=32,epochs=20,validation_split=0.1,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.4 GiB for an array with shape (59751, 100, 100, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-738fc38153ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#vgg = VGG16(input_shape=X.shape[1:], weights='imagenet', include_top=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.4 GiB for an array with shape (59751, 100, 100, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "X=np.array(X/255.0)\n",
    "y=np.array(y)\n",
    "print(X.shape)\n",
    "\n",
    "#vgg = VGG16(input_shape=X.shape[1:], weights='imagenet', include_top=False)\n",
    "res = ResNet50(input_shape=X.shape[1:], weights='imagenet', include_top=False)\n",
    "# don't train existing weights\n",
    "for layer in res.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "print(np.shape(res.output))\n",
    "x = Flatten()(res.output)\n",
    "\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "print(np.shape(x))\n",
    "prediction = Dense(np.shape(X)[0], activation='softmax')(x)\n",
    "\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=res.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "#model.summary()\n",
    "\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "model.fit(X,y,epochs=2,validation_split=0.2)\n",
    "# model=tf.keras.models.Sequential()\n",
    "\n",
    "# model.add(  Conv2D(64,(3,3), input_shape=X.shape[1:])  )   \n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(64,(3,3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation(\"sigmoid\"))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#              optimizer=\"adam\",\n",
    "#              metrics=['accuracy'])\n",
    "# model.fit(X,y,batch_size=32,epochs=20,validation_split=0.1,callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
